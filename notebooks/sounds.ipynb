{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc64b37-9f6b-44f1-ae59-691e7fe2af1c",
   "metadata": {},
   "source": [
    "# Sounds from Swarm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873422f4-b37a-404f-99ba-8644afe4f0e5",
   "metadata": {},
   "source": [
    "Currently generating sound from MAG_LR (F)\n",
    "\n",
    "Sound processing based on work by Nikolai Linden-Vørnle: https://gitlab.gbar.dtu.dk/s183730/sonification-ESA-Swarm/\n",
    "\n",
    "References:\n",
    "\n",
    "- https://resampy.readthedocs.io/\n",
    "- https://pyrubberband.readthedocs.io/\n",
    "- https://panel.holoviz.org/reference/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a1274e-ea59-4c17-9c90-fb3bc28dff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from hapiclient import hapi, hapitime2datetime\n",
    "import resampy\n",
    "import pyrubberband as pyrb\n",
    "\n",
    "import panel as pn\n",
    "\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638f8003-f2e8-4966-9bfd-87f47c1b0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time inputs, to be made configurable\n",
    "t0 = dt.datetime(2022, 1, 16, 0, 0, 0)\n",
    "# t1 = t0 + dt.timedelta(minutes=1)\n",
    "t1 = dt.datetime(2022, 1, 18, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1612361-6c4d-4ebf-b7aa-214cd0e1b7f7",
   "metadata": {},
   "source": [
    "## Data access through VirES+HAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767a4c19-9b22-4823-afb4-12a0ca86855e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(t0, t1) -> pd.DataFrame:\n",
    "    \"\"\"Fetch data from VirES HAPI\n",
    "    \n",
    "    This needs to be done in chunks due to the limit, x_maxTimeSelection\n",
    "    \"\"\"\n",
    "    # Generate time chunks\n",
    "    times = pd.date_range(start=t0, end=t1, freq=\"D\").to_pydatetime()\n",
    "    start_times = times[:-1]\n",
    "    end_times = times[1:]\n",
    "    # Build dataframe in chunks of _df\n",
    "    df = pd.DataFrame()\n",
    "    for start_time, end_time in zip(start_times, end_times):\n",
    "        # Fetch data\n",
    "        data, meta = hapi(\n",
    "            \"https://vires.services/hapi/\",\n",
    "            \"SW_OPER_MAGA_LR_1B\",\n",
    "            \"Latitude,Longitude,Radius,F\",  # ,B_NEC\",\n",
    "            start_time.isoformat(),\n",
    "            end_time.isoformat(),\n",
    "        )\n",
    "        # Convert to dataframe\n",
    "        #  To fix: this will not work with vector, e.g. B_NEC\n",
    "        _df = pd.DataFrame(columns=data.dtype.names, data=data)\n",
    "        _df = _df.set_index(\"Timestamp\")\n",
    "        _df.index = hapitime2datetime(_df.index.values.astype(str))\n",
    "        _df.index = _df.index.tz_convert(\"UTC\").tz_convert(None)\n",
    "        df = pd.concat([df, _df])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba594081-fce6-404e-8c00-4c790c938b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_data(t0, t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb351f3-57db-4891-be59-d78da03a9507",
   "metadata": {},
   "source": [
    "## Sound processing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3b4bd-aad3-4f08-ab79-7d5cf4de2ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x):\n",
    "    \"\"\"Normalise signal to +1/-1 range\"\"\"\n",
    "    return (x - np.average(x)) / (np.ptp(x))\n",
    "\n",
    "\n",
    "def highpass_filter(x, filter_order=8, cutoff_freq=0.0001, fs=1):\n",
    "    \"\"\"Apply butterworth highpass filter to remove DC offset\"\"\"\n",
    "    sos = signal.butter(filter_order, cutoff_freq, 'highpass', fs=fs, output='sos')\n",
    "    # w, h = signal.sosfreqz(sos)\n",
    "    return signal.sosfilt(sos, x)\n",
    "\n",
    "\n",
    "def resample(x, fs=44100, resampling_factor=7):\n",
    "    \"\"\"Resample to new frequency\"\"\"\n",
    "    sr_new = int(fs / resampling_factor)\n",
    "    return resampy.resample(x, fs, sr_new)\n",
    "\n",
    "\n",
    "def smooth_edges(x, fs=44100, t_fade=0.1):\n",
    "    \"\"\"Smoothing window to avoid clicks and pops at the start and end of the signal\"\"\"\n",
    "    window = np.ones(len(x))\n",
    "    L = int(t_fade * fs)\n",
    "    fade = np.linspace(0, 1, L)\n",
    "    for i in range(L):\n",
    "        window[i] *= fade[i]\n",
    "        window[len(window)-1-i] *= fade[i]\n",
    "    return x * window\n",
    "\n",
    "\n",
    "def time_stretch(x, fs=44100, target_length=10):\n",
    "    \"\"\"Stretch duration to target_length (seconds)\"\"\"\n",
    "    input_length = len(x) / fs\n",
    "    ts_ratio = input_length / target_length\n",
    "    return pyrb.time_stretch(x, fs, ts_ratio)\n",
    "\n",
    "\n",
    "def pitch_shift(x, fs=44100, octaves=1):\n",
    "    \"\"\"Shift the pitch by a given number of octaves\"\"\"\n",
    "    return pyrb.pitch_shift(x, fs, 12*octaves)\n",
    "\n",
    "\n",
    "def sound_format(x):\n",
    "    \"\"\"Convert to int16 for audio output\"\"\"\n",
    "    return np.int16(x*32767)\n",
    "\n",
    "\n",
    "def get_sound_pane(x, fs=44100):\n",
    "    \"\"\"Generate panel Audio pane\"\"\"\n",
    "    return pn.pane.Audio(x, sample_rate=fs, sizing_mode=\"stretch_width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb0909-7705-461a-8982-49b6b3d69a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(x, fs=1, resampling_factor=1, ymax=0.00125, figsize=(5, 5)):\n",
    "    nperseg = 2**(16 + (1 - (int(0.5 + resampling_factor/2))))\n",
    "    f, t, Sxx = signal.spectrogram(x, fs, mode='magnitude', nperseg=nperseg)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    ax.pcolormesh(t, f, Sxx[:], shading='gouraud', cmap='hot')\n",
    "    ax.set_ylabel('Frequency [Hz]')\n",
    "    ax.set_xlabel('Time [sec]')\n",
    "    ax.set_ylim(0, ymax)\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333896bb-d97b-4341-afb5-05fe1ea8bf35",
   "metadata": {},
   "source": [
    "### Take a look at the input..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76e80d-d9f2-406a-a25f-866caa6287a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_in = df[\"F\"].values\n",
    "# plot_spectrogram(x_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce172616-f8ca-4056-a099-6d81f448d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The raw input WARNING FOR YOUR EARS!\n",
    "# get_sound_pane(sound_format(x_in))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afe23b4-b59a-47bf-8214-740359eeb5d3",
   "metadata": {},
   "source": [
    "### Now apply a pipeline created from the functions above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29440b6-7373-44c8-9a8e-4d56a715b70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_audio_pipeline(x, target_length=10, shift_octaves=1):\n",
    "    x = normalise(x)\n",
    "    x = highpass_filter(x, filter_order=8, cutoff_freq=0.0001, fs=1)\n",
    "    x = resample(x, fs=44100, resampling_factor=7)\n",
    "    x = smooth_edges(x, fs=44100, t_fade=0.1)\n",
    "    x = time_stretch(x, fs=44100, target_length=target_length)\n",
    "    x = pitch_shift(x, fs=44100, octaves=shift_octaves)\n",
    "    # plot_spectrogram(x, fs=44100, resampling_factor=7, ymax=800)\n",
    "    return x\n",
    "\n",
    "premade_audio_data = apply_audio_pipeline(df[\"F\"].values, target_length=10, shift_octaves=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd8e7c9-896a-48eb-82f4-a7ec1ff6ee2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(premade_audio_data, fs=44100, resampling_factor=7, ymax=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd588bf4-b01a-4d6a-8890-7681cbedbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sound_pane(\n",
    "    sound_format(premade_audio_data),\n",
    "    fs=44100\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb5b69d-efd7-4c77-99c5-96e0e0cdf50c",
   "metadata": {},
   "source": [
    "## Panel dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad7952-b592-410e-b3db-d95a08e3aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundDashboard:\n",
    "    def __init__(self, df=df, t0=t0, t1=t1):\n",
    "        \"\"\"Initialise with the data from above, and create Panel objects\"\"\"\n",
    "        self.default_t0t1 = t0, t1\n",
    "        # self.df = fetch_data(t0, t1)\n",
    "        self.df = df  # use the pre-fetched data from above for speed\n",
    "        # self.audio_data = apply_audio_pipeline(self.df[\"F\"].values)\n",
    "        self.audio_data = premade_audio_data  # use the premade data from above for speed\n",
    "        spectrogram_in = plot_spectrogram(self.df[\"F\"].values)\n",
    "        spectrogram_out = plot_spectrogram(self.audio_data, fs=44100, resampling_factor=7, ymax=800)\n",
    "        wavfilename = self.write_file_for_download()\n",
    "        self.widgets = {\n",
    "            \"time_range\": pn.widgets.DatetimeRangeInput(\n",
    "                start=dt.datetime(2021, 1, 1, 0, 0, 0), end=dt.datetime(2022, 3, 1, 0, 0, 0),\n",
    "                value=(t0, t1)\n",
    "            ),\n",
    "            \"button1\": pn.widgets.Button(\n",
    "                name=\"Fetch data\", button_type=\"primary\"\n",
    "            ),\n",
    "            \"loading1\": pn.indicators.Progress(active=False, sizing_mode=\"stretch_width\"),\n",
    "            \"target_length\": pn.widgets.IntSlider(\n",
    "                name=\"Output length (seconds)\",\n",
    "                start=1, end=60, step=1, value=10\n",
    "            ),\n",
    "            \"shift_octaves\": pn.widgets.IntSlider(\n",
    "                name=\"Shift by number of octaves\",\n",
    "                start=0, end=6, value=1\n",
    "            ),\n",
    "            \"button2\": pn.widgets.Button(\n",
    "                name=\"Regenerate sound ➡️\", button_type=\"primary\"\n",
    "            ),\n",
    "            \"loading2\": pn.indicators.Progress(active=False, sizing_mode=\"stretch_width\"),\n",
    "            \"file_download\": pn.widgets.FileDownload(file=wavfilename)\n",
    "        }\n",
    "        self.panes = {\n",
    "            \"audio\": get_sound_pane(sound_format(self.audio_data)),\n",
    "            \"spectrogram_in\": pn.pane.Matplotlib(spectrogram_in),\n",
    "            \"spectrogram_out\": pn.pane.Matplotlib(spectrogram_out)\n",
    "        }\n",
    "        self.widgets[\"button1\"].on_click(self.update_data)\n",
    "        self.widgets[\"button2\"].on_click(self.update_audio)\n",
    "        \n",
    "    def update_data(self, event):\n",
    "        \"\"\"Fetch the data from VirES and reset the dashboard\"\"\"\n",
    "        t0, t1 = self.widgets[\"time_range\"].value\n",
    "        if (t1 - t0) > dt.timedelta(days=7):\n",
    "            self.widgets[\"button1\"].name = \"Time > 7 days not allowed !\"\n",
    "            self.widgets[\"time_range\"].value = self.default_t0t1\n",
    "            sleep(3)\n",
    "            self.widgets[\"button1\"].name = \"Fetch data\"\n",
    "            return None\n",
    "        self.widgets[\"button1\"].name = \"Busy...\"\n",
    "        self.widgets[\"loading1\"].active = True\n",
    "        self.df = fetch_data(t0, t1)\n",
    "        spectrogram_in = plot_spectrogram(self.df[\"F\"].values)\n",
    "        self.panes[\"spectrogram_in\"].object = spectrogram_in\n",
    "        self.widgets[\"button1\"].name = \"Fetch data\"\n",
    "        self.widgets[\"loading1\"].active = False\n",
    "        self.update_audio(None)\n",
    "\n",
    "    def update_audio(self, event):\n",
    "        \"\"\"Update the output spectrogram and audio\"\"\"\n",
    "        self.panes[\"audio\"].paused = True\n",
    "        self.widgets[\"button2\"].name = \"Busy...\"\n",
    "        # Change contents of audio and spectrogram\n",
    "        self.widgets[\"loading2\"].active = True\n",
    "        x = apply_audio_pipeline(\n",
    "            self.df[\"F\"].values,\n",
    "            target_length=self.widgets[\"target_length\"].value,\n",
    "            shift_octaves=self.widgets[\"shift_octaves\"].value\n",
    "        )\n",
    "        self.audio_data = x\n",
    "        self.panes[\"audio\"].object = sound_format(x)\n",
    "        spectrogram_out = plot_spectrogram(x, fs=44100, resampling_factor=7, ymax=800)\n",
    "        self.panes[\"spectrogram_out\"].object = spectrogram_out\n",
    "        self.write_file_for_download()\n",
    "        # Reset button & loading widget\n",
    "        self.widgets[\"button2\"].name = \"Regenerate sound ➡️\"\n",
    "        self.widgets[\"loading2\"].active = False\n",
    "        \n",
    "    def write_file_for_download(self, filename=\"sonification.wav\"):\n",
    "        wavfile.write(filename, 44100, sound_format(self.audio_data))\n",
    "        return filename\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"GridSpec-based layout of all the widgets and panes\"\"\"\n",
    "        gspec = pn.GridSpec(sizing_mode=\"stretch_both\", max_height=800)\n",
    "        gspec[:, 0] = pn.Column(\n",
    "            pn.pane.Markdown(\"## Input data\"),\n",
    "            pn.pane.Markdown(\"`SW_OPER_MAGA_LR_1B: F`\"),\n",
    "            self.widgets[\"time_range\"],\n",
    "            self.widgets[\"button1\"],\n",
    "            self.widgets[\"loading1\"],\n",
    "            pn.pane.Markdown(\"## Input spectrogram\"),\n",
    "            self.panes[\"spectrogram_in\"]\n",
    "        )\n",
    "        gspec[:, 1] = pn.Column(\n",
    "            self.widgets[\"target_length\"],\n",
    "            self.widgets[\"shift_octaves\"],\n",
    "            self.widgets[\"button2\"],\n",
    "            background=\"WhiteSmoke\"\n",
    "        )\n",
    "        gspec[:, 2] = pn.Column(\n",
    "            pn.pane.Markdown(\"## Output spectrogram & audio\"),\n",
    "            self.widgets[\"loading2\"],\n",
    "            self.panes[\"spectrogram_out\"],\n",
    "            self.panes[\"audio\"],\n",
    "            self.widgets[\"file_download\"]\n",
    "        )\n",
    "        return gspec\n",
    "        \n",
    "\n",
    "SoundDashboard().display().servable(\"Sounds from Swarm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
