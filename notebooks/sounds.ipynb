{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc64b37-9f6b-44f1-ae59-691e7fe2af1c",
   "metadata": {},
   "source": [
    "# Sounds from Swarm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "873422f4-b37a-404f-99ba-8644afe4f0e5",
   "metadata": {},
   "source": [
    "Currently generating sound from MAG_LR (F)\n",
    "\n",
    "Sound processing based on work by Nikolai Linden-VÃ¸rnle: https://gitlab.gbar.dtu.dk/s183730/sonification-ESA-Swarm/\n",
    "\n",
    "References:\n",
    "\n",
    "- https://resampy.readthedocs.io/\n",
    "- https://pyrubberband.readthedocs.io/\n",
    "- https://panel.holoviz.org/reference/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a1274e-ea59-4c17-9c90-fb3bc28dff22",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from time import sleep\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from hapiclient import hapi, hapitime2datetime\n",
    "import resampy\n",
    "import pyrubberband as pyrb\n",
    "\n",
    "from swarmx.toolboxes.tfa import tfalib\n",
    "\n",
    "import panel as pn\n",
    "\n",
    "pn.extension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638f8003-f2e8-4966-9bfd-87f47c1b0c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time inputs, to be made configurable\n",
    "t0 = dt.datetime(2022, 1, 16, 0, 0, 0)\n",
    "# t1 = t0 + dt.timedelta(minutes=1)\n",
    "t1 = dt.datetime(2022, 1, 18, 0, 0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1612361-6c4d-4ebf-b7aa-214cd0e1b7f7",
   "metadata": {},
   "source": [
    "## Data access through VirES+HAPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87789a3-a1ca-4aa3-899b-204606b558b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(t0, t1) -> pd.DataFrame:\n",
    "    \"\"\"Fetch data from VirES HAPI\n",
    "    \"\"\"\n",
    "    if isinstance(t0, dt.datetime):\n",
    "        t0 = t0.isoformat()\n",
    "        t1 = t1.isoformat()\n",
    "    data, meta = hapi(\n",
    "        \"https://vires.services/hapi/\",\n",
    "        \"SW_OPER_MAGA_LR_1B\",\n",
    "        \"Latitude,Longitude,Radius,F\",  # ,B_NEC\",\n",
    "        t0,\n",
    "        t1,\n",
    "    )\n",
    "    # Convert to dataframe\n",
    "    #  To fix: this will not work with vector, e.g. B_NEC\n",
    "    df = pd.DataFrame(columns=data.dtype.names, data=data)\n",
    "    df = df.set_index(\"Timestamp\")\n",
    "    df.index = hapitime2datetime(df.index.values.astype(str))\n",
    "    df.index = df.index.tz_convert(\"UTC\").tz_convert(None)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47dcb05-e471-4a89-9e0e-3a853247d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = fetch_data(t0, t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb351f3-57db-4891-be59-d78da03a9507",
   "metadata": {},
   "source": [
    "## Sound processing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc3b4bd-aad3-4f08-ab79-7d5cf4de2ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise(x):\n",
    "    \"\"\"Normalise signal to +1/-1 range\"\"\"\n",
    "    return (x - np.average(x)) / (np.ptp(x))\n",
    "\n",
    "\n",
    "def highpass_filter(x, filter_order=8, cutoff_freq=0.0001, fs=1):\n",
    "    \"\"\"Apply butterworth highpass filter to remove DC offset\"\"\"\n",
    "    sos = signal.butter(filter_order, cutoff_freq, 'highpass', fs=fs, output='sos')\n",
    "    # w, h = signal.sosfreqz(sos)\n",
    "    return signal.sosfilt(sos, x)\n",
    "\n",
    "\n",
    "def resample(x, fs=44100, resampling_factor=7):\n",
    "    \"\"\"Resample to new frequency\"\"\"\n",
    "    sr_new = int(fs / resampling_factor)\n",
    "    return resampy.resample(x, fs, sr_new)\n",
    "\n",
    "\n",
    "def smooth_edges(x, fs=44100, t_fade=0.1):\n",
    "    \"\"\"Smoothing window to avoid clicks and pops at the start and end of the signal\"\"\"\n",
    "    window = np.ones(len(x))\n",
    "    L = int(t_fade * fs)\n",
    "    fade = np.linspace(0, 1, L)\n",
    "    for i in range(L):\n",
    "        window[i] *= fade[i]\n",
    "        window[len(window)-1-i] *= fade[i]\n",
    "    return x * window\n",
    "\n",
    "\n",
    "def time_stretch(x, fs=44100, target_length=10):\n",
    "    \"\"\"Stretch duration to target_length (seconds)\"\"\"\n",
    "    input_length = len(x) / fs\n",
    "    ts_ratio = input_length / target_length\n",
    "    return pyrb.time_stretch(x, fs, ts_ratio)\n",
    "\n",
    "\n",
    "def pitch_shift(x, fs=44100, octaves=1):\n",
    "    \"\"\"Shift the pitch by a given number of octaves\"\"\"\n",
    "    return pyrb.pitch_shift(x, fs, 12*octaves)\n",
    "\n",
    "\n",
    "def sound_format(x):\n",
    "    \"\"\"Convert to int16 for audio output\"\"\"\n",
    "    return np.int16(x*32767)\n",
    "\n",
    "\n",
    "def get_sound_pane(x, fs=44100):\n",
    "    \"\"\"Generate panel Audio pane\"\"\"\n",
    "    return pn.pane.Audio(x, sample_rate=fs, sizing_mode=\"stretch_width\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53fb0909-7705-461a-8982-49b6b3d69a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_spectrogram(x, fs=1, resampling_factor=1, ymax=0.00125, figsize=(5, 5)):\n",
    "    nperseg = 2**(16 + (1 - (int(0.5 + resampling_factor/2))))\n",
    "    f, t, Sxx = signal.spectrogram(x, fs, mode='magnitude', nperseg=nperseg)\n",
    "    fig, ax = plt.subplots(1, 1, figsize=figsize)\n",
    "    ax.pcolormesh(t, f, Sxx[:], shading='gouraud', cmap='hot')\n",
    "    ax.set_ylabel('Frequency [Hz]')\n",
    "    ax.set_xlabel('Time [sec]')\n",
    "    ax.set_ylim(0, ymax)\n",
    "    plt.close()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d52bae5-37e1-42c1-bb5a-aab2951951e9",
   "metadata": {},
   "source": [
    "### Wavelet analysis from SwarmX:TFA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259cad14-cabf-4885-b042-0f498cde8b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WaveletAnalysis:\n",
    "\n",
    "    def __init__(self, x, sampling_rate=1, cutoff=3/1000, minScale=2, maxScale=1000, dx_wave=1, dj=0.1):\n",
    "        self.x = x\n",
    "        self.sampling_rate = sampling_rate\n",
    "        self.cutoff = cutoff\n",
    "        self.minScale = minScale\n",
    "        self.maxScale = maxScale\n",
    "        self.dx_wave = dx_wave\n",
    "        self.dj = dj\n",
    "        self.highpass_filter_chebysev()\n",
    "        self.wavelet_transform()\n",
    "\n",
    "    def highpass_filter_chebysev(self):\n",
    "        self.x2 = tfalib.filter(self.x, self.sampling_rate, self.cutoff)\n",
    "\n",
    "    def wavelet_transform(self):\n",
    "        W, scales = tfalib.wavelet_transform(self.x2, self.dx_wave, tfalib.morlet_wave, self.minScale, self.maxScale, dj=self.dj)\n",
    "        self.W = W\n",
    "        self.scales = scales\n",
    "\n",
    "    def plot_spectrogram_of_wavelet_transform(self):\n",
    "        x2 = self.x2\n",
    "        W = self.W\n",
    "        scales = self.scales\n",
    "        dj = self.dj\n",
    "        log2scales = np.log2(scales)\n",
    "        W2 = np.abs(W)**2\n",
    "        vmin = np.percentile(W2.flatten(), 2)\n",
    "        vmax = np.percentile(W2.flatten(), 98)\n",
    "        plt.imshow(W2[::-1, :], aspect=\"auto\", extent=(x2[0], x2[-1], log2scales[0], log2scales[-1]), vmin=vmin, vmax=vmax)\n",
    "        plt.yticks(\n",
    "            np.arange(log2scales[0], log2scales[-1] + dj),\n",
    "            labels=2**np.arange(log2scales[0], log2scales[-1] + dj)\n",
    "        )\n",
    "\n",
    "    def flatten_wavelet_transform(self):\n",
    "        return np.sum(np.abs(self.W), axis=0)\n",
    "\n",
    "\n",
    "def transform_using_wavelets(x, sampling_rate=1, cutoff=3/1000, minScale=2, maxScale=1000, dx_wave=1, dj=0.1):\n",
    "    wavelets_out = WaveletAnalysis(x, sampling_rate=sampling_rate, cutoff=cutoff, minScale=minScale, maxScale=maxScale, dx_wave=dx_wave, dj=dj)\n",
    "    return wavelets_out.flatten_wavelet_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee86e149-130c-47c8-bfd3-12591868367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wavelets_out = WaveletAnalysis(df[\"F\"].values)\n",
    "# wavelets_out.plot_spectrogram_of_wavelet_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0ef90c-0477-47fb-9e87-5fed6f09668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(wavelets_out.flatten_wavelet_transform())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b579e435-18b9-40d5-9875-4414ef7ef102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# audio_data = apply_audio_pipeline(wavelets_out.flatten_wavelet_transform())\n",
    "# plot_spectrogram(audio_data, fs=44100, resampling_factor=7, ymax=800)\n",
    "# get_sound_pane(\n",
    "#     sound_format(audio_data),\n",
    "#     fs=44100\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333896bb-d97b-4341-afb5-05fe1ea8bf35",
   "metadata": {},
   "source": [
    "### Take a look at the input..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce76e80d-d9f2-406a-a25f-866caa6287a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_in = df[\"F\"].values\n",
    "# plot_spectrogram(x_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce172616-f8ca-4056-a099-6d81f448d47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The raw input WARNING FOR YOUR EARS!\n",
    "# get_sound_pane(sound_format(x_in))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8afe23b4-b59a-47bf-8214-740359eeb5d3",
   "metadata": {},
   "source": [
    "### Now apply a pipeline created from the functions above..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b86207-b245-404f-b421-ed49155bbeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_audio_pipeline(x, target_length=10, shift_octaves=1, transform=False, transform_kwargs=dict()):\n",
    "    if transform:\n",
    "        x = transform_using_wavelets(x, **transform_kwargs)\n",
    "    x = normalise(x)\n",
    "    x = highpass_filter(x, filter_order=8, cutoff_freq=0.0001, fs=1)\n",
    "    x = resample(x, fs=44100, resampling_factor=7)\n",
    "    x = smooth_edges(x, fs=44100, t_fade=0.1)\n",
    "    x = time_stretch(x, fs=44100, target_length=target_length)\n",
    "    x = pitch_shift(x, fs=44100, octaves=shift_octaves)\n",
    "    # plot_spectrogram(x, fs=44100, resampling_factor=7, ymax=800)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b369e1-8936-4b06-8296-29991d612121",
   "metadata": {},
   "outputs": [],
   "source": [
    "premade_audio_data = apply_audio_pipeline(df[\"F\"].values, target_length=10, shift_octaves=1)\n",
    "# plot_spectrogram(premade_audio_data, fs=44100, resampling_factor=7, ymax=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd588bf4-b01a-4d6a-8890-7681cbedbc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_sound_pane(\n",
    "#     sound_format(premade_audio_data),\n",
    "#     fs=44100\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2734ebe-35fe-4760-97ef-8af76f35fe89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# premade_audio_data_transformed = apply_audio_pipeline(df[\"F\"].values, target_length=10, shift_octaves=1, transform=True)\n",
    "# plot_spectrogram(premade_audio_data_transformed, fs=44100, resampling_factor=7, ymax=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faf6f55-3f01-45db-8607-27bab5aa09d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_sound_pane(\n",
    "#     sound_format(premade_audio_data_transformed),\n",
    "#     fs=44100\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb5b69d-efd7-4c77-99c5-96e0e0cdf50c",
   "metadata": {},
   "source": [
    "## Panel dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ad7952-b592-410e-b3db-d95a08e3aa3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoundDashboard:\n",
    "    def __init__(self, df=df, t0=t0, t1=t1):\n",
    "        \"\"\"Initialise with the data from above, and create Panel objects\"\"\"\n",
    "        self.default_t0t1 = t0, t1\n",
    "        # self.df = fetch_data(t0, t1)\n",
    "        self.df = df  # use the pre-fetched data from above for speed\n",
    "        # self.audio_data = apply_audio_pipeline(self.df[\"F\"].values)\n",
    "        self.audio_data = premade_audio_data  # use the premade data from above for speed\n",
    "        spectrogram_in = plot_spectrogram(self.df[\"F\"].values)\n",
    "        spectrogram_out = plot_spectrogram(self.audio_data, fs=44100, resampling_factor=7, ymax=800)\n",
    "        wavfilename = self.write_file_for_download()\n",
    "        self.widgets = {\n",
    "            \"time_range\": pn.widgets.DatetimeRangeInput(\n",
    "                start=dt.datetime(2021, 1, 1, 0, 0, 0), end=dt.datetime(2022, 3, 1, 0, 0, 0),\n",
    "                value=(t0, t1)\n",
    "            ),\n",
    "            \"button1\": pn.widgets.Button(\n",
    "                name=\"Fetch data\", button_type=\"primary\"\n",
    "            ),\n",
    "            \"loading1\": pn.indicators.Progress(active=False, sizing_mode=\"stretch_width\"),\n",
    "            \"wavelet_transform_checkbox\": pn.widgets.Checkbox(name=\"Apply wavelet transform:\"),\n",
    "            \"target_length\": pn.widgets.IntSlider(\n",
    "                name=\"Output length (seconds)\",\n",
    "                start=1, end=60, step=1, value=10\n",
    "            ),\n",
    "            \"shift_octaves\": pn.widgets.IntSlider(\n",
    "                name=\"Shift by number of octaves\",\n",
    "                start=0, end=6, value=1\n",
    "            ),\n",
    "            \"button2\": pn.widgets.Button(\n",
    "                name=\"Regenerate sound â¡ï¸\", button_type=\"primary\"\n",
    "            ),\n",
    "            \"loading2\": pn.indicators.Progress(active=False, sizing_mode=\"stretch_width\"),\n",
    "            \"file_download\": pn.widgets.FileDownload(file=wavfilename)\n",
    "        }\n",
    "        self.widgets_wavelet_transform = {\n",
    "            \"sampling_rate\": pn.widgets.EditableFloatSlider(name=\"Sampling rate\", start=0.1, end=10, value=1, step=0.01),\n",
    "            \"cutoff\": pn.widgets.EditableFloatSlider(name=\"Cutoff frequency\", start=0.001, end=0.01, value=0.003, step=0.0001),\n",
    "            \"minScale\": pn.widgets.EditableFloatSlider(name=\"Wavelet smallest scale\", start=1, end=100, value=2, step=1),\n",
    "            \"maxScale\": pn.widgets.EditableFloatSlider(name=\"Wavelet largest scale\", start=200, end=2000, value=1000, step=1),\n",
    "            \"dx_wave\": pn.widgets.EditableFloatSlider(name=\"Data time step\", start=0.1, end=10, value=1, step=0.1),\n",
    "            \"dj\": pn.widgets.EditableFloatSlider(name=\"Step size for scales for wavelet transform\", start=0.05, end=0.15, value=0.1, step=0.01),\n",
    "        }\n",
    "        self.panes = {\n",
    "            \"audio\": get_sound_pane(sound_format(self.audio_data)),\n",
    "            \"spectrogram_in\": pn.pane.Matplotlib(spectrogram_in),\n",
    "            \"spectrogram_out\": pn.pane.Matplotlib(spectrogram_out)\n",
    "        }\n",
    "        self.widgets[\"button1\"].on_click(self.update_data)\n",
    "        self.widgets[\"button2\"].on_click(self.update_audio)\n",
    "\n",
    "    def update_data(self, event):\n",
    "        \"\"\"Fetch the data from VirES and reset the dashboard\"\"\"\n",
    "        t0, t1 = self.widgets[\"time_range\"].value\n",
    "        if (t1 - t0) > dt.timedelta(days=7):\n",
    "            self.widgets[\"button1\"].name = \"Time > 7 days not allowed !\"\n",
    "            self.widgets[\"time_range\"].value = self.default_t0t1\n",
    "            sleep(3)\n",
    "            self.widgets[\"button1\"].name = \"Fetch data\"\n",
    "            return None\n",
    "        self.widgets[\"button1\"].name = \"Busy...\"\n",
    "        self.widgets[\"loading1\"].active = True\n",
    "        self.df = fetch_data(t0, t1)\n",
    "        try:\n",
    "            spectrogram_in = plot_spectrogram(self.df[\"F\"].values)\n",
    "        except KeyError:\n",
    "            self.widgets[\"button1\"].name = \"Missing data for this time...\"\n",
    "            self.widgets[\"time_range\"].value = self.default_t0t1\n",
    "            sleep(3)\n",
    "            self.widgets[\"button1\"].name = \"Fetch data\"\n",
    "            self.widgets[\"loading1\"].active = False\n",
    "            return None\n",
    "        self.panes[\"spectrogram_in\"].object = spectrogram_in\n",
    "        self.widgets[\"button1\"].name = \"Fetch data\"\n",
    "        self.widgets[\"loading1\"].active = False\n",
    "        self.update_audio(None)\n",
    "\n",
    "    def update_audio(self, event):\n",
    "        try:\n",
    "            self._update_audio()\n",
    "        except Exception:\n",
    "            self.widgets[\"button2\"].name = \"Oops! Something went wrong\"\n",
    "            self.widgets[\"loading2\"].active = False\n",
    "\n",
    "    def _update_audio(self):\n",
    "        \"\"\"Update the output spectrogram and audio\"\"\"\n",
    "        self.panes[\"audio\"].paused = True\n",
    "        self.widgets[\"button2\"].name = \"Busy...\"\n",
    "        # Change contents of audio and spectrogram\n",
    "        self.widgets[\"loading2\"].active = True\n",
    "        # Extract kwargs to pass to the wavelet transform\n",
    "        wavelet_transform_kwargs = {k: v.value for k, v in self.widgets_wavelet_transform.items()}\n",
    "        # Apply the pipeline\n",
    "        x = apply_audio_pipeline(\n",
    "            self.df[\"F\"].values,\n",
    "            target_length=self.widgets[\"target_length\"].value,\n",
    "            shift_octaves=self.widgets[\"shift_octaves\"].value,\n",
    "            transform=self.widgets[\"wavelet_transform_checkbox\"].value,\n",
    "            transform_kwargs=wavelet_transform_kwargs\n",
    "        )\n",
    "        self.audio_data = x\n",
    "        self.panes[\"audio\"].object = sound_format(x)\n",
    "        spectrogram_out = plot_spectrogram(x, fs=44100, resampling_factor=7, ymax=800)\n",
    "        self.panes[\"spectrogram_out\"].object = spectrogram_out\n",
    "        self.write_file_for_download()\n",
    "        # Reset button & loading widget\n",
    "        self.widgets[\"button2\"].name = \"Regenerate sound â¡ï¸\"\n",
    "        self.widgets[\"loading2\"].active = False\n",
    "\n",
    "    def write_file_for_download(self, filename=\"sonification.wav\"):\n",
    "        wavfile.write(filename, 44100, sound_format(self.audio_data))\n",
    "        return filename\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"GridSpec-based layout of all the widgets and panes\"\"\"\n",
    "        gspec = pn.GridSpec(sizing_mode=\"stretch_both\", max_height=800)\n",
    "        gspec[:, 0] = pn.Column(\n",
    "            pn.pane.Markdown(\"## 1. Input data\"),\n",
    "            pn.pane.Markdown(\"`SW_OPER_MAGA_LR_1B: F`\"),\n",
    "            self.widgets[\"time_range\"],\n",
    "            self.widgets[\"button1\"],\n",
    "            self.widgets[\"loading1\"],\n",
    "            pn.pane.Markdown(\"### Input spectrogram\"),\n",
    "            self.panes[\"spectrogram_in\"]\n",
    "        )\n",
    "        gspec[:, 1] = pn.Column(\n",
    "            pn.pane.Markdown(\"## 2. Transformations\"),\n",
    "            pn.layout.spacer.VSpacer(max_height=10),\n",
    "            pn.Column(\n",
    "                self.widgets[\"wavelet_transform_checkbox\"],\n",
    "                *self.widgets_wavelet_transform.values(),\n",
    "                pn.pane.Markdown(\"*To apply these, tick the checkbox above*\"),\n",
    "                background=\"WhiteSmoke\",\n",
    "                align=\"center\"\n",
    "            ),\n",
    "            pn.layout.spacer.VSpacer(max_height=10),\n",
    "            pn.Column(\n",
    "                self.widgets[\"target_length\"],\n",
    "                self.widgets[\"shift_octaves\"],\n",
    "                self.widgets[\"button2\"],\n",
    "                background=\"WhiteSmoke\",\n",
    "                align=\"center\"\n",
    "            ),\n",
    "            pn.layout.spacer.VSpacer(max_height=10),\n",
    "            background=\"Snow\"\n",
    "        )\n",
    "        gspec[:, 2] = pn.Column(\n",
    "            pn.pane.Markdown(\"## 3. Output spectrogram & audio\"),\n",
    "            self.widgets[\"loading2\"],\n",
    "            self.panes[\"spectrogram_out\"],\n",
    "            self.panes[\"audio\"],\n",
    "            self.widgets[\"file_download\"]\n",
    "        )\n",
    "        return gspec\n",
    "\n",
    "\n",
    "SoundDashboard().display().servable(\"Sounds from Swarm\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "",
   "name": ""
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
